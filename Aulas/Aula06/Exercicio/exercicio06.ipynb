{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df489ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib. pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn. datasets import load_breast_cancer\n",
    "from sklearn. model_selection import train_test_split\n",
    "from sklearn. preprocessing import StandardScaler\n",
    "\n",
    "# 1. Carregar Dados\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "# 2. Divis o Treino/Teste\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Padroniza o (Essencial para PCA, RFE e Lasso)\n",
    "scaler = StandardScaler ()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print (f\"Dataset carregado: {X. shape [1]} features para análise.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1503c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Selecionar os top 50 genes baseados em estatística ANOVA (f_classif)\n",
    "selector_filter = SelectKBest(score_func=f_classif, k=5) # Outras score functions\n",
    "selector_filter.fit(X_train, y_train)\n",
    "\n",
    "# Quais foram escolhidos? (Máscara booleana)\n",
    "mask = selector_filter.get_support()\n",
    "selected_genes_filter = np.array(data.feature_names)[mask]\n",
    "\n",
    "print(\"--- FILTER METHOD ---\")\n",
    "print(f\"Top 5 Genes mais importantes: {selected_genes_filter[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581c6e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Usaremos Regressão Logística como base\n",
    "estimator = LogisticRegression(max_iter=2000, solver='liblinear')\n",
    "\n",
    "# RFE: Quero que sobrem apenas 20 genes\n",
    "# step=0.1 significa remover 10% das features a cada iteração (para ser rápido)\n",
    "rfe = RFE(estimator=estimator, n_features_to_select=5, step=1)\n",
    "#rfe_cv = RFECV(estimator=estimator, step=0.1)\n",
    "rfe.fit(X_train_scaled, y_train)\n",
    "\n",
    "selected_genes_rfe = np.array(data.feature_names)[rfe.support_]\n",
    "\n",
    "print(\"--- WRAPPER METHOD (RFE) ---\")\n",
    "print(f\"Top 5 Genes mais importantes: {selected_genes_rfe}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e49dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Treino\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Importâncias\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1] # Ordenar decrescente\n",
    "\n",
    "print(\"--- EMBEDDED METHOD (Random Forest) ---\")\n",
    "print(\"Top 5 Genes mais importantes:\")\n",
    "for i in range(5):\n",
    "    print(f\"\\t'{data.feature_names[indices[i]]}': {importances[indices[i]]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8f9e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_train_scaled) # PCA sempre nos dados escalados!\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=y_train, palette='viridis', style=y_train, s=100)\n",
    "plt.title(\"PCA: Projeção 2D dos Pacientes\")\n",
    "plt.xlabel(\"PC1 (Maior Variância)\")\n",
    "plt.ylabel(\"PC2 (Segunda Maior)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038f15e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 1. Instanciar PCA sem limitar o número de componentes\n",
    "# (Ou limitando ao máximo possível, que é o min(n_samples, n_features))\n",
    "pca_full = PCA(n_components=None)\n",
    "pca_full.fit(X_train_scaled)\n",
    "\n",
    "# 2. Calcular a Variância Acumulada\n",
    "cumulative_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "\n",
    "# 3. Determinar matematicamente o corte (Ex: 90%)\n",
    "limite_desejado = 0.90\n",
    "n_components_ideal = np.argmax(cumulative_variance >= limite_desejado) + 1\n",
    "\n",
    "print(f\"Para preservar {limite_desejado*100}% da informação, precisamos de {n_components_ideal} componentes.\")\n",
    "\n",
    "# 4. Plotar o Scree Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(cumulative_variance, marker='o', linestyle='--', color='b')\n",
    "plt.axhline(y=limite_desejado, color='r', linestyle='-', label=f'Corte de {limite_desejado*100}%')\n",
    "plt.axvline(x=n_components_ideal-1, color='r', linestyle='--')\n",
    "plt.xlabel('Número de Componentes')\n",
    "plt.ylabel('Variância Explicada Acumulada')\n",
    "plt.title('Scree Plot: Quantos componentes guardar?')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
