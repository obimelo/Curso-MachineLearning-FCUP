{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "OB_5KCAlSc9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Digit Classification\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "image, label = mnist_test[0]\n",
        "\n",
        "flat_image = image.view(1, 784)\n",
        "\n",
        "mlp_model = nn.Sequential(\n",
        "    nn.Linear(784, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 10)\n",
        ")\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = mlp_model(flat_image)\n",
        "    probabilities = torch.softmax(logits, dim=1)\n",
        "    prediction = torch.argmax(probabilities, dim=1)\n",
        "\n",
        "print(\"--- MLP MNIST CLASSIFICATION TEST ---\")\n",
        "print(f\"Actual Label: {label}\")\n",
        "print(f\"Output Shape: {logits.shape}\") # [1, 10]\n",
        "print(f\"Predicted Class: {prediction.item()}\")\n",
        "print(f\"Confidence in Prediction: {probabilities.max().item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5z16UqtP--D",
        "outputId": "7d79e2d7-247d-48e8-df93-50e554656d5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLP MNIST CLASSIFICATION TEST ---\n",
            "Actual Label: 7\n",
            "Output Shape: torch.Size([1, 10])\n",
            "Predicted Class: 2\n",
            "Confidence in Prediction: 0.1085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting 16 spatial feature maps from a color image.\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "image, label = test_set[0]\n",
        "image_batch = image.unsqueeze(0)\n",
        "\n",
        "conv_layer = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = conv_layer(image_batch)\n",
        "\n",
        "print(\"--- CNN CIFAR-10 TEST ---\")\n",
        "print(f\"Original Image Shape: {image.shape}\")\n",
        "print(f\"After Conv Layer (16 filters): {output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30LM62HXQUzj",
        "outputId": "8c18e11c-0935-464b-bba6-019825a842ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- CNN CIFAR-10 TEST ---\n",
            "Original Image Shape: torch.Size([3, 32, 32])\n",
            "After Conv Layer (16 filters): torch.Size([1, 16, 30, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting t+1 based on a window of 10 previous steps.\n",
        "t = torch.linspace(0, 50, 500)\n",
        "series = torch.sin(t)\n",
        "\n",
        "window_size = 10\n",
        "test_window = series[:window_size].view(1, window_size, 1) # [Batch, Seq, Feature]\n",
        "\n",
        "lstm = nn.LSTM(input_size=1, hidden_size=32, batch_first=True)\n",
        "fc = nn.Linear(32, 1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    out, _ = lstm(test_window)\n",
        "    prediction = fc(out[:, -1, :])\n",
        "\n",
        "print(\"\\n--- RNN SINE WAVE TEST ---\")\n",
        "print(f\"Input Sequence (first 3): {test_window.flatten()[:3].tolist()}\")\n",
        "print(f\"Actual Next Value: {series[window_size].item():.4f}\")\n",
        "print(f\"Model Prediction: {prediction.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qfyu54FCQwrJ",
        "outputId": "c282f5ae-57e1-49ea-f681-604b27840466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- RNN SINE WAVE TEST ---\n",
            "Input Sequence (first 3): [0.0, 0.10003281384706497, 0.19906212389469147]\n",
            "Actual Next Value: 0.8426\n",
            "Model Prediction: -0.1470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating context-aware embeddings for a 4-word sentence.\n",
        "sentence = \"Deep learning is powerful\"\n",
        "vocab = {\"Deep\": 0, \"learning\": 1, \"is\": 2, \"powerful\": 3}\n",
        "tokens = torch.tensor([vocab[w] for w in sentence.split()]).unsqueeze(1) # [Seq_Len, Batch]\n",
        "\n",
        "embed = nn.Embedding(num_embeddings=10, embedding_dim=16)\n",
        "tf_layer = nn.TransformerEncoderLayer(d_model=16, nhead=4)\n",
        "\n",
        "with torch.no_grad():\n",
        "    embedded = embed(tokens)\n",
        "    output = tf_layer(embedded)\n",
        "\n",
        "print(\"\\n--- TRANSFORMER TEXT TEST ---\")\n",
        "print(f\"Input Sentence: '{sentence}'\")\n",
        "print(f\"Token IDs: {tokens.flatten().tolist()}\")\n",
        "print(f\"Output Context Vectors Shape: {output.shape}\") # [4, 1, 16]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2eMtZSGQ9On",
        "outputId": "69e22029-0b30-41d4-969b-79be404e3a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- TRANSFORMER TEXT TEST ---\n",
            "Input Sentence: 'Deep learning is powerful'\n",
            "Token IDs: [0, 1, 2, 3]\n",
            "Output Context Vectors Shape: torch.Size([4, 1, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compressing a digit to 20 numbers and rebuilding it.\n",
        "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "real_digit, _ = mnist_test[0] # A '7'\n",
        "real_digit_flat = real_digit.view(-1, 784)\n",
        "\n",
        "encoder = nn.Linear(784, 20)\n",
        "decoder = nn.Sequential(nn.Linear(20, 400), nn.ReLU(), nn.Linear(400, 784), nn.Sigmoid())\n",
        "\n",
        "with torch.no_grad():\n",
        "    latent_vector = encoder(real_digit_flat)\n",
        "    reconstruction = decoder(latent_vector).view(1, 28, 28)\n",
        "\n",
        "print(\"\\n--- VAE MNIST RECONSTRUCTION TEST ---\")\n",
        "print(f\"Input image pixels: {real_digit.sum().item():.2f}\")\n",
        "print(f\"Reconstructed pixels: {reconstruction.sum().item():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oti6Ze5NRASU",
        "outputId": "67038b9f-253f-4143-e7f1-ab4c3498cc4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- VAE MNIST RECONSTRUCTION TEST ---\n",
            "Input image pixels: 72.37\n",
            "Reconstructed pixels: 392.77\n"
          ]
        }
      ]
    }
  ]
}