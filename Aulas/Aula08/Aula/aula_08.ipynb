{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66c87df819eec34f",
   "metadata": {},
   "source": [
    "# Laboratório Prático: Textos\n",
    "\n",
    "**O Problema do Mundo Real:**\n",
    "Queremos criar um sistema que leia comentários de clientes e diga se eles estão Satisfeitos (Positivo) ou Insatisfeitos (Negativo).\n",
    "O computador não entende português. Ele não sabe o que é a palavra \"Fantástico\". Ele só entende números. A nossa missão é traduzir texto para números e alimentar a nossa Rede Neuronal.\n",
    "\n",
    "Vamos começar por importar as nossas ferramentas.\n",
    "\n",
    "**O que vamos importar?**\n",
    "* `torch`: A biblioteca principal do PyTorch. É como a caixa de ferramentas geral.\n",
    "* `torch.nn`: O módulo de Redes Neuronais (*Neural Networks*). Contém os blocos de construção (camadas, funções de ativação, função de perda).\n",
    "* `torch.optim`: O módulo de Otimizadores. Contém a nossa \"bússola\" para descer a montanha do erro.\n",
    "* `CountVectorizer` (do *scikit-learn*): O nosso tradutor. Ele vai pegar no texto e transformá-lo num \"Saco de Palavras\" (uma lista de contagens numéricas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f852f6210dc9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cac46237054860",
   "metadata": {},
   "source": [
    "## 1. Os Nossos Dados\n",
    "\n",
    "Vamos criar um pequeno conjunto de dados de exemplo. Temos uma lista de frases e uma lista de rótulos (a resposta certa).\n",
    "\n",
    "**A Regra dos Rótulos:**\n",
    "* `1` = Sentimento Positivo\n",
    "* `0` = Sentimento Negativo\n",
    "\n",
    "Em Machine Learning, a rede vai olhar para o texto, tentar adivinhar, e comparar o seu palpite com o rótulo real para aprender com o erro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a39a26aac9c05b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Textos (Comentários de clientes)\n",
    "comentarios = [\n",
    "    \"Adorei o produto, qualidade fantástica\",   # Positivo\n",
    "    \"Péssimo serviço, odiei a experiência\",     # Negativo\n",
    "    \"Muito bom, recomendo a toda a gente\",      # Positivo\n",
    "    \"Dinheiro deitado à rua, não funciona\",     # Negativo\n",
    "    \"Excelente, superou as minhas expectativas\",# Positivo\n",
    "    \"Horrível, nunca mais volto a comprar\",     # Negativo\n",
    "    \"Nada a reclamar, vou voltar\"               # Positivo\n",
    "]\n",
    "\n",
    "# Rótulos (O gabarito: 1 = Positivo, 0 = Negativo)\n",
    "rotulos = [1, 0, 1, 0, 1, 0, 1]\n",
    "\n",
    "print(\"Dados carregados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad782d541f76139",
   "metadata": {},
   "source": [
    "## 2. A Tradução: De Texto para Números (Bag of Words)\n",
    "\n",
    "Agora vamos usar o `CountVectorizer`. Ele funciona assim:\n",
    "1. Lê todos os comentários e cria um **Vocabulário** (uma lista com todas as palavras únicas que apareceram, ignorando maiúsculas e pontuação).\n",
    "2. Transforma cada frase numa lista de números. Cada número diz quantas vezes uma determinada palavra do vocabulário apareceu naquela frase.\n",
    "\n",
    "**Parâmetros e Funções utilizadas:**\n",
    "* `vetorizador.fit_transform(dados)`: Faz duas coisas ao mesmo tempo. O `fit` estuda o texto e constrói o dicionário. O `transform` aplica a tradução matemática.\n",
    "* `.toarray()`: Converte o resultado estranho do scikit-learn numa grelha (matriz) normal de números.\n",
    "* `torch.tensor(dados, dtype=...)`: Converte os números do Python para o formato oficial do PyTorch (Tensores, que podem ir para a Placa Gráfica). O `dtype=torch.float32` indica números com casas decimais (que a rede adora), e `torch.long` indica números inteiros pesados (obrigatório para os rótulos de classe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da1696055c275a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O nosso dicionário tem 32 palavras únicas.\n",
      "\n",
      "Primeiro comentário original: 'Adorei o produto, qualidade fantástica'\n",
      "Primeiro comentário em números: tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Inicializar o tradutor\n",
    "vetorizador = CountVectorizer()\n",
    "\n",
    "# Aprender o vocabulário e traduzir as frases\n",
    "X_numerico = vetorizador.fit_transform(comentarios).toarray()\n",
    "\n",
    "# Vamos descobrir quantas palavras únicas o nosso dicionário aprendeu\n",
    "tamanho_vocabulario = X_numerico.shape[1]\n",
    "print(f\"O nosso dicionário tem {tamanho_vocabulario} palavras únicas.\")\n",
    "\n",
    "# Converter para o formato de Tensores do PyTorch\n",
    "X_tensor = torch.tensor(X_numerico, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(rotulos, dtype=torch.long)\n",
    "\n",
    "# Mostrando o resultado do primeiro comentário convertido\n",
    "print(f\"\\nPrimeiro comentário original: '{comentarios[0]}'\")\n",
    "print(f\"Primeiro comentário em números: {X_tensor[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718073748d5f1730",
   "metadata": {},
   "source": [
    "## 3. Construindo a Rede Neuronal (A Fábrica)\n",
    "\n",
    "Chegou a hora de montar a nossa rede usando a ferramenta `nn.Sequential`. Pense nisto como uma caixa que contém uma linha de montagem. O dado entra no topo e vai passando camada a camada.\n",
    "\n",
    "**As peças da nossa arquitetura:**\n",
    "* `nn.Linear(in_features, out_features)`: É o nosso grupo de \"especialistas\".\n",
    "  * `in_features`: Quantas informações entram? Tem de ser EXATAMENTE igual ao número de palavras do nosso vocabulário. Se a nossa \"receção\" tem 26 palavras, precisamos de 26 balcões de entrada.\n",
    "  * `out_features`: O número de especialistas que queremos nesta camada. Aqui escolhemos 8 (um hiperparâmetro, podíamos ter escolhido 16 ou 32).\n",
    "* `nn.ReLU()`: A Função de Ativação. É o \"tempero\" matemático que zera os números negativos, permitindo à rede aprender padrões complexos (curvas) em vez de apenas linhas retas.\n",
    "* A Última Camada `nn.Linear(8, 2)`: Recebe a informação mastigada pelos 8 especialistas e resume tudo em apenas 2 respostas finais (Pontuação para \"Negativo\" e Pontuação para \"Positivo\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3504727d27c9cbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=32, out_features=8, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=8, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Definindo a arquitetura\n",
    "modelo = nn.Sequential(\n",
    "    # Camada de Entrada -> Camada Oculta\n",
    "    nn.Linear(in_features=tamanho_vocabulario, out_features=8),\n",
    "\n",
    "    # Função de Ativação (O filtro Não-Linear)\n",
    "    nn.ReLU(),\n",
    "\n",
    "    # Camada Oculta -> Camada de Saída (Decisão)\n",
    "    nn.Linear(in_features=8, out_features=2)\n",
    ")\n",
    "\n",
    "print(modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c85a281a87697c4",
   "metadata": {},
   "source": [
    "## 4. Preparando o Treino: O Professor e a Bússola\n",
    "\n",
    "A nossa rede nasceu agora, os seus pesos (as conexões matemáticas) são todos aleatórios. Ela não sabe nada. Precisamos treiná-la.\n",
    "\n",
    "**As ferramentas de treino:**\n",
    "* `nn.CrossEntropyLoss()`: É o \"Professor\" (Função de Perda). Ele compara a resposta da rede com o rótulo verdadeiro e grita: \"Estás muito longe do resultado certo!\". Ele usa internamente a fórmula *Softmax* para problemas de classificação.\n",
    "* `optim.Adam(params, lr)`: A \"Bússola\" (Otimizador). Baseado no erro que o professor gritou, o Adam calcula como rodar os \"botões\" (pesos) da rede para diminuir esse erro.\n",
    "  * `params=modelo.parameters()`: Dizemos à bússola para controlar todos os pesos da nossa rede.\n",
    "  * `lr=0.05`: É a *Learning Rate* (Taxa de Aprendizado). Indica o tamanho do passo que vamos dar ao descer a montanha do erro. Se for muito grande, tropeçamos; se for muito pequeno, não saímos do sítio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3719897412cd24b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# O Professor (Calcula o Erro)\n",
    "funcao_perda = nn.CrossEntropyLoss()\n",
    "\n",
    "# A Bússola (Ajusta os Pesos)\n",
    "otimizador = optim.Adam(params=modelo.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a7fe00062c543e",
   "metadata": {},
   "source": [
    "## 5. O Ciclo de Treino (The Training Loop)\n",
    "\n",
    "A rede aprende por repetição. Uma **Época (Epoch)** ocorre quando a rede lê TODO o conjunto de dados uma vez. Vamos treinar por 50 épocas.\n",
    "\n",
    "**Os 5 Passos Mágicos do PyTorch (dentro do loop):**\n",
    "1. `otimizador.zero_grad()`: Limpa o quadro branco. Apaga a memória de quem teve a culpa no erro anterior.\n",
    "2. `modelo(X_tensor)`: O *Forward Pass*. A rede tenta adivinhar a resposta baseada no que sabe agora.\n",
    "3. `funcao_perda(previsoes, y_tensor)`: Calcula a distância (Loss) entre o palpite da rede e a verdade.\n",
    "4. `erro.backward()`: O *Backpropagation*. O momento \"Apontar o dedo\". A matemática volta de trás para a frente a calcular a culpa (gradiente) de cada peso no erro total.\n",
    "5. `otimizador.step()`: A ação. A bússola diz: \"Já que a culpa foi deste peso, vamos diminuí-lo um pouco\". A rede acaba de ficar ligeiramente mais inteligente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3d13207437c9541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A iniciar o treino...\n",
      "\n",
      "Época 10/50 | Erro atualizado: 0.1008\n",
      "Época 20/50 | Erro atualizado: 0.0008\n",
      "Época 30/50 | Erro atualizado: 0.0000\n",
      "Época 40/50 | Erro atualizado: 0.0000\n",
      "Época 50/50 | Erro atualizado: 0.0000\n",
      "\n",
      "Treino finalizado! A rede decorou a montanha do erro.\n"
     ]
    }
   ],
   "source": [
    "epocas = 50\n",
    "\n",
    "print(\"A iniciar o treino...\\n\")\n",
    "\n",
    "for epoca in range(epocas):\n",
    "\n",
    "    # 1. Limpar gradientes\n",
    "    otimizador.zero_grad()\n",
    "\n",
    "    # 2. Fazer previsões\n",
    "    previsoes = modelo(X_tensor)\n",
    "\n",
    "    # 3. Calcular o erro (Loss)\n",
    "    erro = funcao_perda(previsoes, y_tensor)\n",
    "\n",
    "    # 4. Calcular as culpas (Backpropagation)\n",
    "    erro.backward()\n",
    "\n",
    "    # 5. Atualizar os pesos (Otimizar)\n",
    "    otimizador.step()\n",
    "\n",
    "    # Imprimir o progresso a cada 10 épocas\n",
    "    if (epoca + 1) % 10 == 0:\n",
    "        print(f\"Época {epoca+1}/50 | Erro atualizado: {erro.item():.4f}\")\n",
    "\n",
    "print(\"\\nTreino finalizado! A rede decorou a montanha do erro.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299f2e7c0765c14a",
   "metadata": {},
   "source": [
    "## 6. O Teste Final: O Computador Aprendeu a Ler?\n",
    "\n",
    "Vamos escrever duas frases que a rede **NUNCA** viu na vida. Será que ela consegue generalizar o aprendizado e adivinhar o sentimento?\n",
    "\n",
    "**Passos importantes:**\n",
    "* `vetorizador.transform(textos)`: Note que aqui **NÃO usamos o \"fit\"**, apenas o \"transform\". O nosso dicionário já está fechado. Apenas traduzimos o texto novo usando as regras antigas.\n",
    "* `with torch.no_grad():`: É um aviso ao PyTorch: \"Desliga o cálculo de gradientes. Estamos apenas a fazer um teste, não quero que aprendas nem gastes memória agora.\"\n",
    "* `torch.softmax(saidas, dim=1)`: Pega na pontuação bruta que a rede cospe e transforma-a numa percentagem de certeza (0% a 100%), onde a soma das classes dá 1.\n",
    "* `torch.argmax(probabilidades, dim=1)`: Olha para as duas percentagens e devolve o índice daquela que ganhou (Ex: \"A classe 1 teve 90%, então o argmax responde '1'\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4eaffe034e14cce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A fazer previsões em dados novos...\n",
      "\n",
      "Comentário: 'Achei o produto fantástico e excelente'\n",
      " -> O modelo diz que é: Positivo (Certeza: 100.0%)\n",
      "\n",
      "Comentário: 'Serviço horrível e péssimo'\n",
      " -> O modelo diz que é: Negativo (Certeza: 100.0%)\n",
      "\n",
      "Comentário: 'Nada a reclamar, vou voltar'\n",
      " -> O modelo diz que é: Positivo (Certeza: 100.0%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Frases novas de teste\n",
    "frases_teste = [\n",
    "    \"Achei o produto fantástico e excelente\", # Esperamos Positivo (1)\n",
    "    \"Serviço horrível e péssimo\",             # Esperamos Negativo (0)\n",
    "    \"Nada a reclamar, vou voltar\"             # Esperamos Positivo (1)\n",
    "]\n",
    "\n",
    "# Traduzir as novas frases usando o dicionário que já treinamos\n",
    "X_teste = vetorizador.transform(frases_teste).toarray()\n",
    "X_teste_tensor = torch.tensor(X_teste, dtype=torch.float32)\n",
    "\n",
    "print(\"A fazer previsões em dados novos...\\n\")\n",
    "\n",
    "# Desligar o \"modo de aprendizagem\"\n",
    "with torch.no_grad():\n",
    "    # Passar os dados pela rede\n",
    "    saidas_brutas = modelo(X_teste_tensor)\n",
    "\n",
    "    # Converter pontuações brutas em Probabilidades (%)\n",
    "    probabilidades = torch.softmax(saidas_brutas, dim=1)\n",
    "\n",
    "    # Escolher a classe com maior probabilidade\n",
    "    classes_previstas = torch.argmax(probabilidades, dim=1)\n",
    "\n",
    "# Imprimir o resultado de forma amigável para humanos\n",
    "for i in range(len(frases_teste)):\n",
    "    if classes_previstas[i].item() == 1:\n",
    "        sentimento = \"Positivo\"\n",
    "    else:\n",
    "        sentimento = \"Negativo\"\n",
    "\n",
    "    # Extrair a confiança percentual da classe vencedora\n",
    "    confianca = probabilidades[i][classes_previstas[i]].item() * 100\n",
    "\n",
    "    print(f\"Comentário: '{frases_teste[i]}'\")\n",
    "    print(f\" -> O modelo diz que é: {sentimento} (Certeza: {confianca:.1f}%)\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
